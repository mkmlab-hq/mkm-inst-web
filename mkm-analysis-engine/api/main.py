from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import uvicorn
from google.cloud import bigquery
import json
import numpy as np
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from ai_music_generator import AIMusicGenerator, VoiceAnalysisData, BiometricData, CulturalData, SocialContext
from voice_analyzer import VoiceAnalyzer
from dataclasses import asdict
import base64
import cv2
import mediapipe as mp
# rppg-toolbox ë“± ìµœì‹  ì˜¤í”ˆì†ŒìŠ¤ ë…¼ë¬¸ ê¸°ë°˜ rPPG ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ì˜ˆì‹œ)
# from rppg_toolbox import DeepPhys

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="MKM Lab AI ì–´ë“œë°”ì´ì € API",
    description="BigQuery ê¸°ë°˜ í†µí•© ì§€ì‹ ë¸Œë ˆì¸ì„ í™œìš©í•œ AI ì–´ë“œë°”ì´ì €",
    version="2.0.0"
)

# BigQuery ì„¤ì •
PROJECT_ID = "persona-diary-service"
DATASET_ID = "intelligence"
TABLE_ID = "vectorized_papers"

# BigQuery í´ë¼ì´ì–¸íŠ¸
client = bigquery.Client(project=PROJECT_ID)

# AI ìŒì•… ìƒì„±ê¸° ë° ìŒì„± ë¶„ì„ê¸° ì´ˆê¸°í™”
ai_music_generator = AIMusicGenerator()
voice_analyzer = VoiceAnalyzer()

class AdvisorRequest(BaseModel):
    question: str
    persona_code: Optional[str] = None
    context: Optional[str] = None

class AdvisorResponse(BaseModel):
    answer: str
    confidence: float
    sources: List[dict]
    persona_insight: Optional[str] = None

class VoiceAnalysisRequest(BaseModel):
    audio_data: str  # Base64 encoded audio
    user_context: Optional[Dict[str, Any]] = None

class VoiceAnalysisResponse(BaseModel):
    pitch_frequency: float
    speech_rate: float
    voice_quality: str
    emotional_tone: str
    stress_indicators: float
    jitter: float
    shimmer: float
    hnr: float
    vocal_range: Dict[str, float]
    speech_patterns: Dict[str, float]
    confidence: float
    recommendations: Dict[str, Any]

class MusicGenerationRequest(BaseModel):
    voice_analysis: VoiceAnalysisData
    biometric: BiometricData
    cultural: CulturalData
    social: SocialContext
    user_intention: str

class MusicGenerationResponse(BaseModel):
    music_style: str
    tempo: int
    scale: List[str]
    instruments: List[Dict[str, Any]]
    ai_music_data: Dict[str, Any]
    metadata: Dict[str, Any]
    unique_signature: str

class HealthResponse(BaseModel):
    status: str
    message: str
    bigquery_status: str
    knowledge_count: int

class MolecularScienceRequest(BaseModel):
    compound_name: Optional[str] = None
    target_protein: Optional[str] = None
    disease_area: Optional[str] = None
    research_area: Optional[str] = None

class MolecularScienceResponse(BaseModel):
    compounds: List[Dict[str, Any]]
    targets: List[Dict[str, Any]]
    clinical_trials: List[Dict[str, Any]]
    research_papers: List[Dict[str, Any]]
    insights: Dict[str, Any]

def get_knowledge_data():
    """BigQueryì—ì„œ ì§€ì‹ ë°ì´í„° ë¡œë“œ"""
    try:
        query = f"""
        SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
        LIMIT 100
        """
        query_job = client.query(query)
        results = query_job.result()
        
        data = []
        for row in results:
            row_dict = dict(row.items())
            data.append(row_dict)
        
        return data
    except Exception as e:
        print(f"BigQuery ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def vectorize_text(text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)"""
    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•¨
    import hashlib
    hash_obj = hashlib.md5(text.encode())
    hash_hex = hash_obj.hexdigest()
    
    # í•´ì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ 384ì°¨ì› ë²¡í„° ìƒì„±
    np.random.seed(int(hash_hex[:8], 16))
    vector = np.random.rand(384).tolist()
    return vector

def find_relevant_sources(question: str, knowledge_data: List[dict], top_k: int = 3):
    """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì§€ì‹ ì†ŒìŠ¤ ì°¾ê¸°"""
    if not knowledge_data:
        return []
    
    question_vector = vectorize_text(question)
    
    similarities = []
    for item in knowledge_data:
        if 'vector' in item and item['vector']:
            # ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            try:
                item_vector = item['vector'][:384]  # 384ì°¨ì›ìœ¼ë¡œ ë§ì¶¤
                if len(item_vector) == 384:
                    similarity = cosine_similarity(
                        [question_vector], 
                        [item_vector]
                    )[0][0]
                    similarities.append((similarity, item))
            except:
                continue
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    similarities.sort(key=lambda x: x[0], reverse=True)
    
    # ìƒìœ„ kê°œ ë°˜í™˜
    return [item for _, item in similarities[:top_k]]

def generate_advisor_response(question: str, relevant_sources: List[dict], persona_code: Optional[str] = None) -> str:
    """AI ì–´ë“œë°”ì´ì € ì‘ë‹µ ìƒì„±"""
    
    if not relevant_sources:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œê±°ë‚˜, ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."
    
    # ê´€ë ¨ ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘
    source_info = []
    for source in relevant_sources:
        title = source.get('title', 'ì œëª© ì—†ìŒ')
        summary = source.get('summary', 'ìš”ì•½ ì—†ìŒ')
        source_type = source.get('source_type', 'ì•Œ ìˆ˜ ì—†ìŒ')
        source_info.append(f"â€¢ {title} ({source_type}): {summary}")
    
    # í˜ë¥´ì†Œë‚˜ë³„ ë§ì¶¤ ì‘ë‹µ
    persona_insights = {
        'P1': "ë‹¹ì‹ ì˜ í˜ì‹ ì  ì‚¬ê³ ì™€ ë¦¬ë”ì‹­ ì„±í–¥ì„ ê³ ë ¤í•  ë•Œ, ",
        'P2': "ê· í˜• ì¡íŒ ì ‘ê·¼ ë°©ì‹ì„ ì„ í˜¸í•˜ëŠ” ë‹¹ì‹ ì—ê²ŒëŠ”, ",
        'P3': "í™œë™ì ì´ê³  íƒí—˜ì ì¸ ì„±í–¥ì˜ ë‹¹ì‹ ì—ê²ŒëŠ”, ",
        'P4': "ì‹ ì¤‘í•˜ê³  ë³´í˜¸ì ì¸ ì„±í–¥ì˜ ë‹¹ì‹ ì—ê²ŒëŠ”, "
    }
    
    persona_prefix = persona_insights.get(persona_code, "")
    
    # ì‘ë‹µ ìƒì„±
    response = f"""{persona_prefix}ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€ë“œë¦½ë‹ˆë‹¤:

ğŸ“š **í†µí•© ì§€ì‹ ë¸Œë ˆì¸ ê¸°ë°˜ ë‹µë³€:**

{question}ì— ëŒ€í•œ ë‹µë³€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

ğŸ” **ê´€ë ¨ ì§€ì‹ ì†ŒìŠ¤:**
{chr(10).join(source_info)}

ğŸ’¡ **í•µì‹¬ í†µì°°:**
ìœ„ì˜ ì§€ì‹ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬, ë‹¹ì‹ ì˜ ìƒí™©ì— ê°€ì¥ ì í•©í•œ í•´ê²°ì±…ì„ ì œì‹œí•©ë‹ˆë‹¤. 

ğŸ¯ **ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸:**
1. ë‹¨ê³„ë³„ ì ‘ê·¼ ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤
2. ê°œì¸ì  íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤
3. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ì¡°ì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤

ì´ ë‹µë³€ì€ MKM Labì˜ í†µí•© ì§€ì‹ ë¸Œë ˆì¸ì—ì„œ ì¶”ì¶œí•œ ìµœì‹  ì—°êµ¬ ë°ì´í„°ì™€ ì„ìƒ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."""

    return response

@app.get("/", response_model=HealthResponse)
async def health_check():
    """API ìƒíƒœ í™•ì¸"""
    try:
        knowledge_data = get_knowledge_data()
        bigquery_status = "ì—°ê²°ë¨" if knowledge_data else "ì—°ê²° ì‹¤íŒ¨"
        knowledge_count = len(knowledge_data)
    except:
        bigquery_status = "ì—°ê²° ì‹¤íŒ¨"
        knowledge_count = 0
    
    return HealthResponse(
        status="healthy",
        message="MKM Lab AI ì–´ë“œë°”ì´ì € APIê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤",
        bigquery_status=bigquery_status,
        knowledge_count=knowledge_count
    )

@app.post("/ask-advisor/", response_model=AdvisorResponse)
async def ask_advisor(request: AdvisorRequest):
    """AI ì–´ë“œë°”ì´ì €ì—ê²Œ ì§ˆë¬¸"""
    try:
        # ì§€ì‹ ë°ì´í„° ë¡œë“œ
        knowledge_data = get_knowledge_data()
        
        if not knowledge_data:
            raise HTTPException(status_code=500, detail="ì§€ì‹ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê´€ë ¨ ì†ŒìŠ¤ ì°¾ê¸°
        relevant_sources = find_relevant_sources(request.question, knowledge_data)
        
        # ì‘ë‹µ ìƒì„±
        answer = generate_advisor_response(
            request.question, 
            relevant_sources, 
            request.persona_code
        )
        
        # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
        confidence = min(0.95, 0.7 + len(relevant_sources) * 0.1)
        
        # ì†ŒìŠ¤ ì •ë³´ ì •ë¦¬
        sources = []
        for source in relevant_sources:
            sources.append({
                "title": source.get('title', 'ì œëª© ì—†ìŒ'),
                "source_type": source.get('source_type', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                "url": source.get('url', ''),
                "summary": source.get('summary', '')[:200] + "..."
            })
        
        return AdvisorResponse(
            answer=answer,
            confidence=confidence,
            sources=sources,
            persona_insight=f"í˜ë¥´ì†Œë‚˜ {request.persona_code} ê¸°ë°˜ ë§ì¶¤ ì‘ë‹µ" if request.persona_code else None
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì–´ë“œë°”ì´ì € ì˜¤ë¥˜: {str(e)}")

@app.get("/knowledge-stats/")
async def get_knowledge_stats():
    """ì§€ì‹ ë°ì´í„° í†µê³„"""
    try:
        knowledge_data = get_knowledge_data()
        
        # ì†ŒìŠ¤ íƒ€ì…ë³„ í†µê³„
        source_types = {}
        for item in knowledge_data:
            source_type = item.get('source_type', 'unknown')
            source_types[source_type] = source_types.get(source_type, 0) + 1
        
        return {
            "total_count": len(knowledge_data),
            "source_types": source_types,
            "last_updated": "2025-07-17"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.post("/analyze-voice/", response_model=VoiceAnalysisResponse)
async def analyze_voice(request: VoiceAnalysisRequest):
    """ìŒì„± ë¶„ì„"""
    try:
        audio_data = base64.b64decode(request.audio_data)
        analysis_result = voice_analyzer.analyze_voice(audio_data, request.user_context)
        recommendations = voice_analyzer.get_voice_based_recommendations(analysis_result)
        result_dict = asdict(analysis_result)
        
        return VoiceAnalysisResponse(
            pitch_frequency=result_dict["pitch_frequency"],
            speech_rate=result_dict["speech_rate"],
            voice_quality=result_dict["voice_quality"],
            emotional_tone=result_dict["emotional_tone"],
            stress_indicators=result_dict["stress_indicators"],
            jitter=result_dict["jitter"],
            shimmer=result_dict["shimmer"],
            hnr=result_dict["hnr"],
            vocal_range=result_dict["vocal_range"],
            speech_patterns=result_dict["speech_patterns"],
            confidence=result_dict["confidence"],
            recommendations=recommendations
        )
    except Exception as e:
        fallback = voice_analyzer._generate_fallback_analysis()
        recommendations = voice_analyzer.get_voice_based_recommendations(fallback)
        fallback_dict = asdict(fallback)
        
        return VoiceAnalysisResponse(
            pitch_frequency=fallback_dict["pitch_frequency"],
            speech_rate=fallback_dict["speech_rate"],
            voice_quality=fallback_dict["voice_quality"],
            emotional_tone=fallback_dict["emotional_tone"],
            stress_indicators=fallback_dict["stress_indicators"],
            jitter=fallback_dict["jitter"],
            shimmer=fallback_dict["shimmer"],
            hnr=fallback_dict["hnr"],
            vocal_range=fallback_dict["vocal_range"],
            speech_patterns=fallback_dict["speech_patterns"],
            confidence=fallback_dict["confidence"],
            recommendations=recommendations
        )

@app.post("/generate-music/", response_model=MusicGenerationResponse)
async def generate_music(request: MusicGenerationRequest):
    """AI ìŒì•… ìƒì„±"""
    try:
        # ê°œì¸í™”ëœ ìŒì•… ìƒì„±
        music_data = ai_music_generator.generate_personalized_music(
            request.voice_analysis,
            request.biometric,
            request.cultural,
            request.social,
            request.user_intention
        )
        
        return MusicGenerationResponse(
            music_style=music_data['music_style'],
            tempo=music_data['tempo'],
            scale=music_data['scale'],
            instruments=music_data['instruments'],
            ai_music_data=music_data['ai_music_data'],
            metadata=music_data['metadata'],
            unique_signature=music_data['unique_signature']
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìŒì•… ìƒì„± ì˜¤ë¥˜: {str(e)}")

@app.post("/voice-to-music/")
async def voice_to_music(audio_file: UploadFile = File(...), user_intention: str = "meditation"):
    """ìŒì„±ì—ì„œ ìŒì•…ê¹Œì§€ í†µí•© ì²˜ë¦¬"""
    try:
        # 1. ìŒì„± íŒŒì¼ ì½ê¸°
        audio_data = await audio_file.read()
        
        # 2. ìŒì„± ë¶„ì„
        analysis_result = voice_analyzer.analyze_voice(audio_data)
        
        # 3. ê¸°ë³¸ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ì ë°ì´í„°ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        biometric = BiometricData(
            heart_rate=70.0,
            hrv=50.0,
            stress_level=analysis_result.stress_indicators,
            energy_level=1.0 - analysis_result.stress_indicators,
            sleep_quality=0.7
        )
        
        cultural = CulturalData(
            nationality="Korean",
            cultural_heritage=["korean"],
            traditional_instruments=["gayageum", "daegeum"],
            spiritual_beliefs=["meditation"]
        )
        
        social = SocialContext(
            age_group="30s",
            occupation="professional",
            education_level="university",
            social_status="middle",
            life_stage="career_focused"
        )
        
        # 4. AI ìŒì•… ìƒì„±
        music_data = ai_music_generator.generate_personalized_music(
            analysis_result,
            biometric,
            cultural,
            social,
            user_intention
        )
        
        # 5. í†µí•© ê²°ê³¼ ë°˜í™˜
        return {
            "voice_analysis": {
                "pitch_frequency": analysis_result.pitch_frequency,
                "speech_rate": analysis_result.speech_rate,
                "emotional_tone": analysis_result.emotional_tone,
                "stress_indicators": analysis_result.stress_indicators,
                "confidence": analysis_result.confidence
            },
            "music_generation": {
                "music_style": music_data['music_style'],
                "tempo": music_data['tempo'],
                "scale": music_data['scale'],
                "instruments": [inst['name'] for inst in music_data['instruments']],
                "ai_generated": music_data['ai_music_data'].get('success', False),
                "unique_signature": music_data['unique_signature']
            },
            "recommendations": voice_analyzer.get_voice_based_recommendations(analysis_result)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µí•© ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.post("/molecular-science/", response_model=MolecularScienceResponse)
async def get_molecular_science_data(request: MolecularScienceRequest):
    """ë¶„ìê³¼í•™ ë°ì´í„° ì¡°íšŒ"""
    try:
        # BigQueryì—ì„œ ë¶„ìê³¼í•™ ë°ì´í„° ì¡°íšŒ
        query = f"""
        SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
        WHERE source_type IN ('drug_discovery', 'clinical_trial', 'arxiv_paper')
        """
        
        if request.compound_name:
            query += f" AND (title LIKE '%{request.compound_name}%' OR summary LIKE '%{request.compound_name}%')"
        
        if request.target_protein:
            query += f" AND (title LIKE '%{request.target_protein}%' OR summary LIKE '%{request.target_protein}%')"
        
        if request.disease_area:
            query += f" AND (title LIKE '%{request.disease_area}%' OR summary LIKE '%{request.disease_area}%')"
        
        if request.research_area:
            query += f" AND (title LIKE '%{request.research_area}%' OR summary LIKE '%{request.research_area}%')"
        
        query += " LIMIT 50"
        
        query_job = client.query(query)
        results = query_job.result()
        
        data = []
        for row in results:
            row_dict = dict(row.items())
            data.append(row_dict)
        
        # ë°ì´í„° ë¶„ë¥˜
        compounds = [item for item in data if item.get('source_type') == 'drug_discovery']
        clinical_trials = [item for item in data if item.get('source_type') == 'clinical_trial']
        research_papers = [item for item in data if item.get('source_type') == 'arxiv_paper']
        
        # íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ì •ë³´ ì¶”ì¶œ
        targets = []
        for item in data:
            if item.get('target_proteins'):
                targets.extend(item['target_proteins'])
        
        targets = list(set(targets))  # ì¤‘ë³µ ì œê±°
        targets = [{'name': target, 'count': sum(1 for item in data if item.get('target_proteins') and target in item['target_proteins'])} for target in targets]
        
        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = {
            'total_compounds': len(compounds),
            'total_trials': len(clinical_trials),
            'total_papers': len(research_papers),
            'top_targets': sorted(targets, key=lambda x: x['count'], reverse=True)[:5],
            'research_areas': list(set([item.get('research_area', '') for item in data if item.get('research_area')])),
            'clinical_phases': list(set([item.get('clinical_phase', '') for item in data if item.get('clinical_phase')]))
        }
        
        return MolecularScienceResponse(
            compounds=compounds,
            targets=targets,
            clinical_trials=clinical_trials,
            research_papers=research_papers,
            insights=insights
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ìê³¼í•™ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/molecular-science/stats/")
async def get_molecular_science_stats():
    """ë¶„ìê³¼í•™ ë°ì´í„° í†µê³„"""
    try:
        query = f"""
        SELECT 
            source_type,
            COUNT(*) as count,
            AVG(molecular_weight) as avg_molecular_weight,
            AVG(drug_likeness) as avg_drug_likeness,
            AVG(bioavailability) as avg_bioavailability
        FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
        WHERE source_type IN ('drug_discovery', 'clinical_trial', 'arxiv_paper')
        GROUP BY source_type
        """
        
        query_job = client.query(query)
        results = query_job.result()
        
        stats = []
        for row in results:
            stats.append({
                'source_type': row.source_type,
                'count': row.count,
                'avg_molecular_weight': row.avg_molecular_weight,
                'avg_drug_likeness': row.avg_drug_likeness,
                'avg_bioavailability': row.avg_bioavailability
            })
        
        return {
            'molecular_science_stats': stats,
            'total_records': sum(stat['count'] for stat in stats),
            'last_updated': datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.post("/analyze-face/")
async def analyze_face(video: UploadFile = File(...)):
    """ìµœì‹  ë…¼ë¬¸/ì˜¤í”ˆì†ŒìŠ¤ ê¸°ë°˜ 15ì´ˆ ì´ìƒ ì˜ìƒ ì–¼êµ´ ë¶„ì„(rPPG+ì–¼êµ´ íŠ¹ì§•+AI/ML ê¸°ì§ˆ ì˜ˆì¸¡)"""
    # 1. ì˜ìƒ íŒŒì¼ ì €ì¥ ë° í”„ë ˆì„ ì¶”ì¶œ
    video_bytes = await video.read()
    with open("temp_video.mp4", "wb") as f:
        f.write(video_bytes)
    cap = cv2.VideoCapture("temp_video.mp4")
    frames = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)
    cap.release()

    # 2. ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ (mediapipe)
    mp_face = mp.solutions.face_mesh
    face_mesh = mp_face.FaceMesh(static_image_mode=False)
    landmarks = []
    for frame in frames:
        results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        if results.multi_face_landmarks:
            landmarks.append(results.multi_face_landmarks[0])
    # (íŠ¹ì§• ë²¡í„°í™” ì½”ë“œ ì¶”ê°€)

    # 3. rPPG ì‹ í˜¸ ì¶”ì¶œ (ë”¥ëŸ¬ë‹ ê¸°ë°˜, ì˜ˆì‹œ)
    # rppg_model = DeepPhys()  # ì‹¤ì œ ì˜¤í”ˆì†ŒìŠ¤ êµ¬ì¡°ì— ë§ê²Œ ì´ˆê¸°í™”
    # rppg_signal = rppg_model.extract(frames)
    # heart_rate = rppg_model.estimate_heart_rate(rppg_signal)
    # (í˜ˆì••, ìŠ¤íŠ¸ë ˆìŠ¤ ë“± ì¶”ê°€)
    heart_rate = 72  # ìƒ˜í”Œ ë”ë¯¸ê°’
    signal_quality = 0.92  # ìƒ˜í”Œ ë”ë¯¸ê°’

    # 4. ML/DL ê¸°ë°˜ ê¸°ì§ˆ ì˜ˆì¸¡ (ìƒ˜í”Œ)
    features = np.array([0.5]*10)  # ì–¼êµ´ íŠ¹ì§• + rPPG ì‹ í˜¸ ë²¡í„° (ìƒ˜í”Œ)
    # model = joblib.load("disposition_model.pkl")
    # disposition_scores = model.predict(features.reshape(1, -1))
    disposition_scores = {
        "thinking": 65,
        "introversion": 55,
        "driving": 60,
        "practical": 50,
        "stable": 70
    }  # ìƒ˜í”Œ ë”ë¯¸ê°’

    # 5. í˜ë¥´ì†Œë‚˜ ë§¤í•‘ ë° ìµœì‹  ë…¼ë¬¸/íŠ¹í—ˆ ê·¼ê±° ìƒ˜í”Œ
    persona = "P2: The Balanced Builder"
    reference_papers = [
        {"title": "DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks", "url": "https://arxiv.org/abs/1805.08367"},
        {"title": "Meta-rPPG: Remote Heart Rate Estimation Using a Meta-Learning Framework", "url": "https://arxiv.org/abs/2007.12468"}
    ]

    return {
        "heart_rate": heart_rate,
        "signal_quality": signal_quality,
        "disposition_scores": disposition_scores,
        "persona": persona,
        "landmarks_count": len(landmarks),
        "reference_papers": reference_papers
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000) 