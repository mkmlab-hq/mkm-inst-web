#!/usr/bin/env python3
Google Magentaë¥¼ í™œìš©í•œ AI ìŒì•… ìƒì„± í”„ë¡œí† íƒ€ì…
ê°œì¸í™”ëœ ìŒì•… ìƒì„±ì˜ í•µì‹¬ ì—”ì§„
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
import numpy as np

# Magenta ê´€ë ¨ import (ì‹¤ì œ ì„¤ì¹˜ ì‹œ)
try:
    from magenta.models.music_vae import configs
    from magenta.models.music_vae.trained_model import TrainedModel
    from magenta.protobuf import music_pb2    from magenta.music import midi_io
    from magenta.music import constants
    MAGENTA_AVAILABLE = trueexcept ImportError:
    MAGENTA_AVAILABLE = False
    print("âš ï¸ Magentaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

class PersonalizedMusicGenerator:
    í™”ëœ ìŒì•… ìƒì„±ê¸°"   
    def __init__(self):
        self.musical_scales = {
            korean:[object Object]
                pyeongjo: ['C,D,E,F, 'G', 'A',B'],
                gyemyeonjo:C,D,E',F#, 'G', 'A',B]    },
            western:[object Object]             major: ['C,D,E,F, 'G', 'A',B'],
                minor: ['C,D,E,F, A',B]    },
            eastern:[object Object]                raga:C,D,E',F#, 'G', 'A',B'],
                pentatonic: ['C',D',E',G', 'A]    },
            meditative:[object Object]           natural: ['C,D,E,F, 'G', 'A',B'],
                drone: ['C,D,E,F, A',B']
            }
        }
        
        self.instruments = {
            korean:[object Object]               gayageum:[object Object]range': (4884character':deep_natural},
                daegeum:[object Object]range': (6084haracter':bright_clear},
                janggu:[object Object]range': (3648, 'character': 'rhythmic'},
                piri:[object Object]range': (6084ter: onal}    },
            western:[object Object]             piano: {'range': (21, 108character': 'versatile'},
                violin:[object Object]range': (5584), character: warm_emotional'},
                cello:[object Object]range': (3672character': 'deep_rich'},
                flute:[object Object]range': (6084haracter: airy}    },
            eastern:[object Object]
                sitar:[object Object]range': (4884), character': 'mystical_spiritual'},
                tabla:[object Object]range': (3648, 'character':rhythmic_complex'},
                bansuri:[object Object]range': (6084aracter': 'natural_breathy'},
                tanpura:[object Object]range': (4872, 'character': 'drone_sustained}    },
            meditative:[object Object]           singing_bowl:[object Object]range': (4872character:resonant_peaceful'},
                chimes:[object Object]range': (6084, 'character: ethereal_clear'},
                drone:[object Object]range': (3660), character': 'sustained_meditative'},
                nature_sounds:[object Object]range': (4872aracter': 'organic_natural'}
            }
        }
        
        # Magenta ëª¨ë¸ ì´ˆê¸°í™”
        self.magenta_model = None
        if MAGENTA_AVAILABLE:
            self._initialize_magenta_model()
    
    def _initialize_magenta_model(self):
       Magenta ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # MusicVAE ëª¨ë¸ ë¡œë“œ
            model_config = configs.CONFIG_MAP['cat-mel_2bar_big']
            self.magenta_model = TrainedModel(model_config, batch_size=4, checkpoint_dir_or_path=None)
            print("âœ… Magenta ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ Magenta ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.magenta_model = None
    
    def generate_personalized_music(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
       ìŒì•… ìƒì„±""        
        # 1. ìŒì•… ìŠ¤íƒ€ì¼ ê²°ì •
        style = self._determine_music_style(user_data)
        
        # 2. ìŒê³„ ê²°ì •
        scale = self._determine_musical_scale(user_data, style)
        
        # 3. í…œí¬ ê²°ì •
        tempo = self._determine_tempo(user_data)
        
        # 4. ì•…ê¸° ì„ íƒ
        instruments = self._select_instruments(user_data, style)
        
        #5 ìƒì„±
        melody = self._generate_melody(scale, user_data)
        
        #6ìƒì„±
        harmony = self._generate_harmony(scale, user_data)
        
        # 7. ë¦¬ë“¬ ìƒì„±
        rhythm = self._generate_rhythm(user_data)
        
        # 8. ìŒì•… ì¡°í•©
        music_data = self._combine_music_elements(
            melody, harmony, rhythm, tempo, instruments, user_data
        )
        
        return music_data
    
    def _determine_music_style(self, user_data: Dict[str, Any]) -> str:
       ìŠ¤íƒ€ì¼ ê²°ì •""
        cultural_heritage = user_data.get(cultural_heritage',       stress_level = user_data.get(stress_level', 0.5)
        intention = user_data.get('intention', '').lower()
        
        # ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë†’ìœ¼ë©´ ëª…ìƒ ìŠ¤íƒ€ì¼
        if stress_level > 0.7:
            return 'meditative        
        # ì˜ë„ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼ ê²°ì •
        if 'meditation' in intention or 'peace' in intention:
            return 'meditative        
        # ë¬¸í™”ì  ë°°ê²½ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼
        if 'korean' in cultural_heritage:
            return 'korean'
        elif 'eastern' in cultural_heritage:
            returneastern'
        else:
            return western'
    
    def _determine_musical_scale(self, user_data: Dict[str, Any], style: str) -> Liststr]:
        stress_level = user_data.get(stress_level', 00.5      energy_level = user_data.get(energy_level', 0.5)
        emotional_tone = user_data.get('emotional_tone', 'balanced')
        
        # ìŠ¤íƒ€ì¼ë³„ ê¸°ë³¸ ìŒê³„
        if style == 'korean':
            base_scales = self.musical_scales['korean']
            if stress_level > 0.6            return base_scales[gyemyeonjo']  # ê³„ë©´ì¡° (ì–´ë‘ìš´ ëŠë‚Œ)
            else:
                return base_scales[pyeongjo']    # í‰ì¡° (ë°ì€ ëŠë‚Œ)
        
        elif style == 'western':
            base_scales = self.musical_scales['western']
            if stress_level > 0.6 or emotional_tone == 'calming:            return base_scales[minor]       # ë§ˆì´ë„ˆ (ì–´ë‘ìš´ ëŠë‚Œ)
            else:
                return base_scales[major]       # ë©”ì´ì € (ë°ì€ ëŠë‚Œ)
        
        elif style == 'eastern':
            base_scales = self.musical_scales['eastern']
            if energy_level > 0.7            return base_scales[raga]        # ë¼ê°€ (ë³µì¡í•œ ëŠë‚Œ)
            else:
                return base_scalespentatonic']  # 5ìŒê³„ (ë‹¨ìˆœí•œ ëŠë‚Œ)
        
        else:  # meditative
            base_scales = self.musical_scales['meditative']
            return base_scales[natural]         # ìì—°ìŠ¤ëŸ¬ìš´ ìŒê³„
    
    def _determine_tempo(self, user_data: Dict[str, Any]) -> int:
  ì •"""
        heart_rate = user_data.get(heart_rate', 70      stress_level = user_data.get(stress_level', 00.5      energy_level = user_data.get(energy_level', 00.5       speech_rate = user_data.get(speech_rate, 120)  # ë¶„ë‹¹ ë‹¨ì–´ ìˆ˜
        
        base_tempo = 120        
        # ì‹¬ë°•ìˆ˜ì— ë”°ë¥¸ ì¡°ì •
        if heart_rate > 80:
            base_tempo += 20
        elif heart_rate < 60:
            base_tempo -= 20        
        # ìŠ¤íŠ¸ë ˆìŠ¤ì— ë”°ë¥¸ ì¡°ì •
        if stress_level > 0.7:
            base_tempo -= 30
        elif stress_level < 0.3:
            base_tempo += 15        
        # ì—ë„ˆì§€ ë ˆë²¨ì— ë”°ë¥¸ ì¡°ì •
        if energy_level > 0.7:
            base_tempo += 15
        elif energy_level < 0.3:
            base_tempo -= 15        
        # ë§í•˜ê¸° ì†ë„ì— ë”°ë¥¸ ì¡°ì •
        if speech_rate > 150:
            base_tempo += 10
        elif speech_rate < 100:
            base_tempo -= 10        
        # í…œí¬ ë²”ìœ„ ì œí•œ (60PM)
        return max(60in(180base_tempo))
    
    def _select_instruments(self, user_data: Dict[str, Any], style: str) -> List[Dict[str, Any]]:
  
        intention = user_data.get('intention', ').lower()
        stress_level = user_data.get(stress_level', 00.5      energy_level = user_data.get(energy_level', 0.5)
        
        available_instruments = self.instruments[style]
        selected_instruments = []
        
        # ê¸°ë³¸ ì•…ê¸° 2ê°œ ì„ íƒ
        instrument_names = list(available_instruments.keys())[:2]
        
        for instrument_name in instrument_names:
            instrument_data = available_instruments[instrument_name].copy()
            instrument_data['name'] = instrument_name
            
            # ê°œì¸í™”ëœ ì•…ê¸° ì„¤ì •
            if stress_level > 0.7
                # ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë†’ìœ¼ë©´ ë¶€ë“œëŸ¬ìš´ ìŒìƒ‰
                instrument_data['volume'] = 00.6        instrument_data['reverb'] = 0.8            else:
                # ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë‚®ìœ¼ë©´ ì„ ëª…í•œ ìŒìƒ‰
                instrument_data['volume'] = 00.8        instrument_data['reverb'] =0.4      
            selected_instruments.append(instrument_data)
        
        # ëª…ìƒ ì˜ë„ê°€ ìˆìœ¼ë©´ ëª…ìƒ ì•…ê¸° ì¶”ê°€
        if 'meditation' in intention or 'peace' in intention:
            meditative_instruments = self.instruments['meditative']
            singing_bowl = meditative_instruments['singing_bowl'].copy()
            singing_bowl[name] = 'singing_bowl'
            singing_bowl['volume'] = 0.5
            singing_bowl['reverb'] = 1.0
            selected_instruments.append(singing_bowl)
        
        return selected_instruments
    
    def _generate_melody(self, scale: List[str], user_data: Dict[str, Any]) -> List[Dict[str, Any]]:
   ë©œë¡œë”” ìƒì„±
        emotional_tone = user_data.get('emotional_tone', 'balanced')
        energy_level = user_data.get(energy_level', 0.5)
        
        melody = []
        num_notes = 8  #8ë””
        
        for i in range(num_notes):
            if emotional_tone == 'joyful:
                # ê¸°ìœ ê°ì •: ìƒìŠ¹í•˜ëŠ” íŒ¨í„´
                note_index = (i * 2) % len(scale)
            elif emotional_tone == 'calming:
                # í‰ì˜¨í•œ ê°ì •: í•˜ê°•í•˜ëŠ” íŒ¨í„´
                note_index = (len(scale) - 1 - (i *3scale)
            else:
                # ê· í˜•ì¡íŒ ê°ì •: ìì—°ìŠ¤ëŸ¬ìš´ íŒ¨í„´
                note_index = i % len(scale)
            
            # ìŒí‘œ ì •ë³´ ìƒì„±
            note_data =[object Object]
                note: scale[note_index],
                duration': 00.5 if energy_level > 0.6 else 10,  # ì—ë„ˆì§€ì— ë”°ë¥¸ ì§€ì†ì‹œê°„
               velocity:80 if emotional_tone == joyful' else60ê°•ë„
                octave: 4 + (i % 2),  # ì˜¥íƒ€ë¸Œ ë³€í™”
              position': i  # ìœ„ì¹˜ ì •ë³´
            }
            
            melody.append(note_data)
        
        return melody
    
    def _generate_harmony(self, scale: List[str], user_data: Dict[str, Any]) -> List[Dict[str, Any]]:
   í•˜ëª¨ë‹ˆ ìƒì„±      stress_level = user_data.get(stress_level', 0.5)
        emotional_tone = user_data.get('emotional_tone', 'balanced')
        
        harmony = []
        
        # ê°ì •ì— ë”°ë¥¸ í™”ìŒ ì„ íƒ
        if emotional_tone == 'joyful:
            # ê¸°ìœ ê°ì •: ë©”ì´ì € í™”ìŒ
            chord_progression = ['major,major,major, 'major']
        elif emotional_tone == 'calming:
            # í‰ì˜¨í•œ ê°ì •: ë§ˆì´ë„ˆ í™”ìŒ
            chord_progression = ['minor,minor,minor, 'minor']
        else:
            # ê· í˜•ì¡íŒ ê°ì •: í˜¼í•© í™”ìŒ
            chord_progression = ['major,minor,majorminor]
        
        for i, chord_type in enumerate(chord_progression):
            chord_data =[object Object]
                type': chord_type,
               root': scale[i % len(scale)],
               duration: 2.0,  # í™”ìŒ ì§€ì†ì‹œê°„
               velocity': 50,   # í™”ìŒ ê°•ë„
                position: i * 2  # ìœ„ì¹˜ ì •ë³´
            }
            harmony.append(chord_data)
        
        return harmony
    
    def _generate_rhythm(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
  ì„±"""
        heart_rate = user_data.get(heart_rate', 70      stress_level = user_data.get(stress_level', 00.5      energy_level = user_data.get(energy_level', 0.5)
        
        # ê¸°ë³¸ ë¦¬ë“¬ íŒ¨í„´
        if stress_level > 07:
            # ìŠ¤íŠ¸ë ˆìŠ¤ ë†’ìŒ: ë‹¨ìˆœí•œ ë¦¬ë“¬
            pattern = 1, 0, 0 0, 1 0, 0, 0/4 ë°•ì, ê°•ë°•ë§Œ
        elif energy_level > 07:
            # ì—ë„ˆì§€ ë†’ìŒ: ë³µì¡í•œ ë¦¬ë“¬
            pattern = 1, 0, 1 0, 1 0, 1, 0]  # 4/4 ë°•ì, ëª¨ë“  ë°•ì
        else:
            # ê· í˜•ì¡íŒ ìƒíƒœ: ì¤‘ê°„ ë³µì¡ë„
            pattern = 1, 0, 0 1, 1 0, 0, 1]  # 4/4 ë°•ì, ì¤‘ê°„ íŒ¨í„´
        
        rhythm_data = {
            pattern': pattern,
           time_signature': 4/4',
            subdivision': 8,  # 8ë¶„ìŒí‘œ ë‹¨ìœ„
      intensity': energy_level,
           complexity': 10 - stress_level  # ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë‚®ì„ìˆ˜ë¡ ë³µì¡
        }
        
        return rhythm_data
    
    def _combine_music_elements(self, melody: List[Dict], harmony: List[Dict], 
                              rhythm: Dict, tempo: int, instruments: List[Dict], 
                              user_data: Dict[str, Any]) -> Dict[str, Any]:
     ìš”ì†Œ ì¡°í•©""        
        # ê°œì¸í™”ëœ ìŒì•… ë°ì´í„° ìƒì„±
        music_data = {
         style: self._determine_music_style(user_data),
         scale: self._determine_musical_scale(user_data, self._determine_music_style(user_data)),
          tempotempo,
        instruments': instruments,
            melodyelody,
            harmony': harmony,
            rhythmhythm,
            duration: 30.0,  # 30ì´ˆ ìŒì•…
           key': 'C',  # ê¸°ë³¸ ì¡°ì„±
           time_signature': rhythm['time_signature'],
            personalization_factors':[object Object]
                heart_rate: user_data.get('heart_rate', 70),
             stress_level: user_data.get(stress_level', 0.5),
             energy_level: user_data.get(energy_level', 0.5),
               emotional_tone: user_data.get('emotional_tone', 'balanced'),
                cultural_heritage: user_data.get(cultural_heritage', []),
               intention:user_data.get('intention, )    },
       generation_timestamp:datetime.now().isoformat(),
       ai_model': PersonalizedMusicGenerator_v1.0'
        }
        
        return music_data
    
    def generate_midi_file(self, music_data: Dict[str, Any], output_path: str) -> bool:
       I íŒŒì¼ ìƒì„±"""
        try:
            if MAGENTA_AVAILABLE and self.magenta_model:
                # Magentaë¥¼ ì‚¬ìš©í•œ MIDI ìƒì„±
                return self._generate_midi_with_magenta(music_data, output_path)
            else:
                # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: MIDI êµ¬ì¡°ë§Œ ìƒì„±
                return self._generate_midi_simulation(music_data, output_path)
        except Exception as e:
            print(f"âŒ MIDI íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _generate_midi_with_magenta(self, music_data: Dict[str, Any], output_path: str) -> bool:
     Magentaë¥¼ ì‚¬ìš©í•œ MIDI ìƒì„±"""
        try:
            # Magenta ëª¨ë¸ì„ ì‚¬ìš©í•œ ìŒì•… ìƒì„±
            # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Magenta APIë¥¼ ì‚¬ìš©)
            print(ğŸµ Magentaë¥¼ ì‚¬ìš©í•œ ìŒì•… ìƒì„± ì¤‘...")
            
            # ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œ Magenta í˜¸ì¶œ ëŒ€ì‹  êµ¬ì¡°ë§Œ ìƒì„±
            midi_structure =[object Object]
          tracks   [object Object]                   name               notes:music_data['melody'],
                   instrument': music_data['instruments'][0]['name']
                    },
    [object Object]                 name': 'Harmony',
                    notes': music_data['harmony'],
                   instrument': music_data['instruments'][1]['name'] if len(music_datainstruments']) > 1 else 'piano'
                    }
                ],
            tempo: music_data['tempo'],
               time_signature': music_data[time_signature']
            }
            
            # MIDI íŒŒì¼ë¡œ ì €ì¥ (ì‹œë®¬ë ˆì´ì…˜)
            with open(output_path, 'w') as f:
                json.dump(midi_structure, f, indent=2)
            
            print(f"âœ… MIDI íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            return true          
        except Exception as e:
            print(fâŒ Magenta MIDI ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _generate_midi_simulation(self, music_data: Dict[str, Any], output_path: str) -> bool:
      ë ˆì´ì…˜ ëª¨ë“œ MIDI ìƒì„±"""
        try:
            # ì‹œë®¬ë ˆì´ì…˜ MIDI êµ¬ì¡° ìƒì„±
            midi_structure =[object Object]
            format': 'simulation,
          tracks   [object Object]                   name               notes:music_data['melody'],
                   instrument': music_data['instruments'][0]['name']
                    },
    [object Object]                 name': 'Harmony',
                    notes': music_data['harmony'],
                   instrument': music_data['instruments'][1]['name'] if len(music_datainstruments']) > 1 else 'piano'
                    }
                ],
            tempo: music_data['tempo'],
               time_signature': music_data['time_signature'],
               duration': music_data['duration'],
                personalization': music_data[personalization_factors']
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥ (ì‹¤ì œ MIDI ëŒ€ì‹ )
            with open(output_path, 'w') as f:
                json.dump(midi_structure, f, indent=2)
            
            print(f"âœ… ì‹œë®¬ë ˆì´ì…˜ MIDI íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            return true          
        except Exception as e:
            print(fâŒ ì‹œë®¬ë ˆì´ì…˜ MIDI ìƒì„± ì‹¤íŒ¨: {e}")
            returnfalse
def demo_personalized_music_generation():
  ê°œì¸í™”ëœ ìŒì•… ìƒì„± ë°ëª¨    
    print(ğŸµ AI ìŒì•… ìƒì„± í”„ë¡œí† íƒ€ì… ë°ëª¨)
    print(=*50)
    
    # ìƒ˜í”Œ ì‚¬ìš©ì ë°ì´í„°
    user_data = {
        heart_rate: 72.0     stress_level': 0.3     energy_level': 0.7,
        cultural_heritage': [korean', 'eastern'],
       emotional_tone': calming',
    intention': 'Peaceful meditation for healthy body and mind',
       age_group': '30s',
     occupation': software_engineer,      speech_rate:130    }
    
    # ìŒì•… ìƒì„±ê¸° ì´ˆê¸°í™”
    music_generator = PersonalizedMusicGenerator()
    
    # ê°œì¸í™”ëœ ìŒì•… ìƒì„±
    print("ğŸ¼ ê°œì¸í™”ëœ ìŒì•… ìƒì„± ì¤‘...")
    music_data = music_generator.generate_personalized_music(user_data)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nâœ… ìŒì•… ìƒì„± ì™„ë£Œ!")
    print(f"ğŸµ ìŠ¤íƒ€ì¼: {music_data['style]})
    print(fâš¡ í…œí¬: {music_data['tempo']} BPM")
    print(fğŸ¸ ì•…ê¸°: {', .join([inst['name'] for inst in music_data['instruments']])}")
    print(fğŸ¼ ìŒê³„: {',.join(music_data['scale])}")
    print(f"â±ï¸ ì§€ì†ì‹œê°„: {music_data['duration']}ì´ˆ")
    
    print(f"\nğŸ¼ ë©œë¡œë”” ({len(music_data['melody'])}ê°œ ìŒí‘œ):)    for i, note in enumerate(music_data['melody'][:4):
        print(f ìŒí‘œ {i+1: {note['note]} (ì§€ì†ì‹œê°„: [object Object]noteduration']}ì´ˆ, ê°•ë„:[object Object]note['velocity']})")
    
    print(f"\nğŸ¶ í•˜ëª¨ë‹ˆ ({len(music_data[harmony'])}ê°œ í™”ìŒ):")
    for i, chord in enumerate(music_data['harmony'][:2):
        print(f"  í™”ìŒ {i+1}: {chord[type']} on [object Object]chord['root']} (ì§€ì†ì‹œê°„: [object Object]chord['duration']}ì´ˆ)")
    
    print(f"\nğŸ¥ ë¦¬ë“¬ íŒ¨í„´: {music_data[rhythm']['pattern']})    
    # MIDI íŒŒì¼ ìƒì„±
    output_path = 'personalized_music_output.json'
    success = music_generator.generate_midi_file(music_data, output_path)
    
    if success:
        print(f"\nğŸ’¾ ìŒì•… íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}) 
    return music_data

if __name__ == "__main__":
    demo_personalized_music_generation() 