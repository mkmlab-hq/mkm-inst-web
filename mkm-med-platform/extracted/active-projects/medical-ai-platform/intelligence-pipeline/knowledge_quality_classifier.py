import json
import numpy as np
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
import re

class KnowledgeQualityClassifier:
    def __init__(self):
        print("ğŸ” ì§€ì‹ í’ˆì§ˆ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”...")
        
        # ë°ì´í„° ì¶œì²˜ë³„ ê°€ì¤‘ì¹˜ ì •ì˜
        self.source_weights = {
            "pubmed": 1,
            "nature": 1,
            "science": 10,
            "lancet": 1,
            "nejm": 10,
            "jama": 10,
            "arxiv": 0.9,
            "ieee": 0.9,
            "acm": 0.9,
            "springer": 0.9,
            "elsevier": 0.9,
            "google_scholar": 0.7,
            "researchgate": 0.7,
            "academia": 0.7,
            "blog": 0.5,
            "community": 0.5,
            "forum": 0.5
        }
        
        # ê·¼ê±° ìˆ˜ì¤€ ë¶„ë¥˜
        self.evidence_levels = {
            "rct": "Level 1 - Randomized Controlled Trial",
            "cohort": "Level 2 - Cohort Study",
            "case_control": "Level 3 - Case-Control Study",
            "case_series": "Level 4 - Case-Series",
            "expert_opinion": "Level 5 - Expert Opinion",
            "preclinical": "Level 6 - Preclinical Study"
        }
        
        print(âœ…ì§€ì‹ í’ˆì§ˆ ë¶„ë¥˜ê¸° ì¤€ë¹„ ì™„ë£Œ")
    
    def classify_evidence_level(self, content, source_type):
        """ê·¼ê±° ìˆ˜ì¤€ ë¶„ë¥˜"""
        content_lower = content.lower()
        
        # RCT í‚¤ì›Œë“œ ê²€ìƒ‰
        rct_keywords = [
            "randomized controlled trial", "rct", "ndomized", "randomised",
            "double-blind", "placebo-controlled,clinical trial"
        ]
        
        # ì½”í˜¸íŠ¸ ì—°êµ¬ í‚¤ì›Œë“œ
        cohort_keywords = [
            "cohort study", "prospective study", "longitudinal study",
            "follow-up study", "observational study"
        ]
        
        # ì¼€ì´ìŠ¤-ì»¨íŠ¸ë¡¤ ì—°êµ¬ í‚¤ì›Œë“œ
        case_control_keywords = [
            "case-control study", "case control", "retrospective study"
        ]
        
        # ì¼€ì´ìŠ¤ ì‹œë¦¬ì¦ˆ í‚¤ì›Œë“œ
        case_series_keywords = [
            "case series", "case report", "case study"
        ]
        
        # ì „ë¬¸ê°€ ì˜ê²¬ í‚¤ì›Œë“œ
        expert_keywords = [
            "expert opinion", "review", "commentary", "perspective"
        ]
        
        # ì „ì„ìƒ ì—°êµ¬ í‚¤ì›Œë“œ
        preclinical_keywords = [
            "in vitro", "in vivo", "animal study", "ical",
            "laboratory study", "l culture"
        ]
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê·¼ê±° ìˆ˜ì¤€ ê²°ì •
        if any(keyword in content_lower for keyword in rct_keywords):
            return self.evidence_levels["rct"]
        elif any(keyword in content_lower for keyword in cohort_keywords):
            return self.evidence_levels["cohort"]
        elif any(keyword in content_lower for keyword in case_control_keywords):
            return self.evidence_levels["case_control"]
        elif any(keyword in content_lower for keyword in case_series_keywords):
            return self.evidence_levels["case_series"]
        elif any(keyword in content_lower for keyword in preclinical_keywords):
            return self.evidence_levels["preclinical"]
        elif any(keyword in content_lower for keyword in expert_keywords):
            return self.evidence_levels["expert_opinion"]
        else:
            return self.evidence_levels["expert_opinion"]  # ê¸°ë³¸ê°’
    
    def calculate_quality_score(self, data_item):
        """ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0        
        # 1. ì¶œì²˜ ê°€ì¤‘ì¹˜ (40)
        source = data_item.get('source_name', '').lower()
        source_weight = 0.5 # ê¸°ë³¸ê°’
        
        for key, weight in self.source_weights.items():
            if key in source:
                source_weight = weight
                break
        
        score += source_weight * 0.4        
        # 2. ê·¼ê±° ìˆ˜ì¤€ ê°€ì¤‘ì¹˜ (30%)
        evidence_level = data_item.get('evidence_level', 'expert_opinion')
        evidence_weights = {
            "rct": 10,
            "cohort": 0.8,
            "case_control": 0.6,
            "case_series": 0.4,
            "expert_opinion": 0.3,
            "preclinical": 0.5
        }
        evidence_weight = evidence_weights.get(evidence_level, 0.3)
        score += evidence_weight * 0.3        
        # 3. ì¸ìš© ê°€ì¤‘ì¹˜ (20%)
        citations = data_item.get('citations', 0)
        citation_score = min(citations / 100.0, 1.0)  # ìµœëŒ€ 100 ì •ê·œí™”
        score += citation_score * 0.2        
        #4. ìµœì‹ ë„ ê°€ì¤‘ì¹˜ (10%)
        published_date = data_item.get('published_date', '')
        if published_date:
            try:
                year = int(published_date[:4])
                current_year = datetime.now().year
                recency_score = max(0, (year - (current_year - 10)) / 10.0)  # ìµœê·¼ 10ë…„ì„ 1.0ìœ¼ë¡œ ì •ê·œí™”
                score += recency_score * 0.1
            except:
                score += 0.5 * 0.1 # ê¸°ë³¸ê°’
        else:
            score += 0.5 * 0.1   
        return min(score, 10.0) # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
    
    def classify_knowledge_data(self, knowledge_data):
        """ì§€ì‹ ë°ì´í„° í’ˆì§ˆ ë¶„ë¥˜ ë° ê°€ì¤‘ì¹˜ ë¶€ì—¬"""
        print("ğŸ” ì§€ì‹ ë°ì´í„° í’ˆì§ˆ ë¶„ë¥˜ ì‹œì‘...")
        
        classified_data = {
            'high_quality': [],  # í’ˆì§ˆ ì ìˆ˜ 0.8 ì´ìƒ
            'medium_quality': [],  # í’ˆì§ˆ ì ìˆ˜ 0.5 ~ 0.79
            'low_quality': [],     # í’ˆì§ˆ ì ìˆ˜ 0.49 ì´í•˜
            'statistics': {
                'total_items': 0,
                'high_quality_count': 0,
                'medium_quality_count': 0,
                'low_quality_count': 0,
                'average_quality_score': 0.0
            }
        }
        
        all_scores = []
        
        # ê° ë°ì´í„° íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
        for data_type, items in knowledge_data.items():
            if data_type in ['collection_date', 'total_items']:
                continue
                
            print(f"[{data_type}] ë¶„ë¥˜ ì¤‘...")
            
            for item in items:
                # ê·¼ê±° ìˆ˜ì¤€ ë¶„ë¥˜
                content = f"{item.get('title', '')} {item.get('content', '')}"
                evidence_level = self.classify_evidence_level(content, item.get('source_name', ''))
                item['evidence_level'] = evidence_level
                
                # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                quality_score = self.calculate_quality_score(item)
                item['quality_score'] = quality_score # í‚¤ ì´ë¦„ ë³€ê²½
                all_scores.append(quality_score)
                
                # í’ˆì§ˆë³„ ë¶„ë¥˜
                if quality_score >= 0.8:
                    classified_data['high_quality'].append(item)
                    classified_data['statistics']['high_quality_count'] += 1
                elif quality_score >= 0.5:
                    classified_data['medium_quality'].append(item)
                    classified_data['statistics']['medium_quality_count'] += 1
                else:
                    classified_data['low_quality'].append(item)
                    classified_data['statistics']['low_quality_count'] += 1
                
                classified_data['statistics']['total_items'] += 1        
        # í†µê³„ ê³„ì‚°
        if all_scores:
            classified_data['statistics']['average_quality_score'] = np.mean(all_scores)
        
        print(f"âœ… í’ˆì§ˆ ë¶„ë¥˜ ì™„ë£Œ!")
        print(f"   ì´ ë°ì´í„°: {classified_data['statistics']['total_items']}ê±´")
        print(f"   ê³ í’ˆì§ˆ: {classified_data['statistics']['high_quality_count']}ê±´")
        print(f"   ì¤‘í’ˆì§ˆ: {classified_data['statistics']['medium_quality_count']}ê±´")
        print(f"   ì €í’ˆì§ˆ: {classified_data['statistics']['low_quality_count']}ê±´")
        print(f"   í‰ê·  í’ˆì§ˆ ì ìˆ˜: {classified_data['statistics']['average_quality_score']:.3f}")
        
        return classified_data
    
    def generate_evidence_based_response(self, query, classified_data):
        """ê·¼ê±° ê¸°ë°˜ AI ì‘ë‹µ ìƒì„±"""
        # ê³ í’ˆì§ˆ ë°ì´í„° ìš°ì„  ì‚¬ìš©
        high_quality_data = classified_data['high_quality']
        medium_quality_data = classified_data['medium_quality']
        
        # ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë°ì´í„° ê²€ìƒ‰ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        relevant_data = []
        
        for item in high_quality_data + medium_quality_data:
            content = f"{item.get('title', '')} {item.get('content', '')}".lower()
            if any(keyword in content for keyword in query.lower().split()):
                relevant_data.append(item)
        
        if not relevant_data:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì—°êµ¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."        
        # í’ˆì§ˆ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        relevant_data.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
        
        # ìƒìœ„ 3ê°œ ë°ì´í„° ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        top_data = relevant_data[:3]
        
        response = f"ìµœì‹  ì—°êµ¬ì— ë”°ë¥´ë©´, {query}ì™€ ê´€ë ¨í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë°œê²¬ì´ ìˆìŠµë‹ˆë‹¤:\n\n"
        for i, data in enumerate(top_data, 1):
            evidence_level = self.evidence_levels.get(data.get('evidence_level', 'expert_opinion'), 'Expert Opinion')
            source = data.get('source_name', 'Unknown')
            year = data.get('published_date', '')[:4] if data.get('published_date') else 'ìë£Œ ì—†ìŒ'
            
            response += f"{i}. {data.get('title', 'ì œëª© ì—†ìŒ')}\n"
            response += f"   ì¶œì²˜: {source} ({year})\n"
            response += f"   ê·¼ê±° ìˆ˜ì¤€: {evidence_level}\n"
            response += f"   í’ˆì§ˆ ì ìˆ˜: {data.get('quality_score', 0):.2f}\n"
        return response

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    classifier = KnowledgeQualityClassifier()
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    sample_data = {
        "medical_research": [
            {
                "title": "Randomized Controlled Trial of rPPG for Stress Detection",
                "content": "This randomized controlled trial demonstrates...",
                "source_name": "pubmed",
                "published_date": "2023",
                "citations": 45
            },
            {
                "title": "Case Study: Facial Analysis in Traditional Medicine",
                "content": "A case study of facial analysis...",
                "source_name": "blog",
                "published_date": "2022",
                "citations": 2
            }
        ]
    }
    
    classified = classifier.classify_knowledge_data(sample_data)
    print("=" * 50)
    print("ê·¼ê±° ê¸°ë°˜ ì‘ë‹µ í…ŒìŠ¤íŠ¸:")
    response = classifier.generate_evidence_based_response("stress detection", classified)
    print(response) 